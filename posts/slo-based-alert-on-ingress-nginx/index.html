<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>How to Configure Alerting on Ingress-NGINX in Kubernetes | Tanmay Bhat</title><meta name=keywords content="ingress,kubernetes,prometheus"><meta name=description content="In this blog post, we will be discussing how to set up monitoring and alerting for Nginx ingress in a Kubernetes environment.
We will cover the installation and configuration of ingress-nginx, Prometheus and Grafana, and the setup of alerts for key Ingress metrics.
Pre-requisites : A Kubernetes cluster Helm v3 Install Prometheus and Grafana In this step, we will install Prometheus to collect metrics, and Grafana to visualize and create alerts based on those metrics."><meta name=author content="Tanmay Bhat"><link rel=canonical href=https://www.aviator.co/blog/how-to-monitor-and-alert-on-nginx-ingress-in-kubernetes/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe+FVUFzPh7U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://tanmay-bhat.github.io/memoji.png><link rel=icon type=image/png sizes=16x16 href=https://tanmay-bhat.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://tanmay-bhat.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://tanmay-bhat.github.io/apple-touch-icon.png><link rel=mask-icon href=https://tanmay-bhat.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-6PXF78BGMY"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6PXF78BGMY",{anonymize_ip:!1})}</script><meta property="og:title" content="How to Configure Alerting on Ingress-NGINX in Kubernetes"><meta property="og:description" content="In this blog post, we will be discussing how to set up monitoring and alerting for Nginx ingress in a Kubernetes environment.
We will cover the installation and configuration of ingress-nginx, Prometheus and Grafana, and the setup of alerts for key Ingress metrics.
Pre-requisites : A Kubernetes cluster Helm v3 Install Prometheus and Grafana In this step, we will install Prometheus to collect metrics, and Grafana to visualize and create alerts based on those metrics."><meta property="og:type" content="article"><meta property="og:url" content="https://tanmay-bhat.github.io/posts/slo-based-alert-on-ingress-nginx/"><meta property="og:image" content="https://tanmay-bhat.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-01-30T00:00:00+00:00"><meta property="article:modified_time" content="2023-01-30T00:00:00+00:00"><meta property="og:site_name" content="Tanmay Bhat"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://tanmay-bhat.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="How to Configure Alerting on Ingress-NGINX in Kubernetes"><meta name=twitter:description content="In this blog post, we will be discussing how to set up monitoring and alerting for Nginx ingress in a Kubernetes environment.
We will cover the installation and configuration of ingress-nginx, Prometheus and Grafana, and the setup of alerts for key Ingress metrics.
Pre-requisites : A Kubernetes cluster Helm v3 Install Prometheus and Grafana In this step, we will install Prometheus to collect metrics, and Grafana to visualize and create alerts based on those metrics."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://tanmay-bhat.github.io/posts/"},{"@type":"ListItem","position":3,"name":"How to Configure Alerting on Ingress-NGINX in Kubernetes","item":"https://tanmay-bhat.github.io/posts/slo-based-alert-on-ingress-nginx/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"How to Configure Alerting on Ingress-NGINX in Kubernetes","name":"How to Configure Alerting on Ingress-NGINX in Kubernetes","description":"In this blog post, we will be discussing how to set up monitoring and alerting for Nginx ingress in a Kubernetes environment.\nWe will cover the installation and configuration of ingress-nginx, Prometheus and Grafana, and the setup of alerts for key Ingress metrics.\nPre-requisites : A Kubernetes cluster Helm v3 Install Prometheus and Grafana In this step, we will install Prometheus to collect metrics, and Grafana to visualize and create alerts based on those metrics.","keywords":["ingress","kubernetes","prometheus"],"articleBody":"In this blog post, we will be discussing how to set up monitoring and alerting for Nginx ingress in a Kubernetes environment.\nWe will cover the installation and configuration of ingress-nginx, Prometheus and Grafana, and the setup of alerts for key Ingress metrics.\nPre-requisites : A Kubernetes cluster Helm v3 Install Prometheus and Grafana In this step, we will install Prometheus to collect metrics, and Grafana to visualize and create alerts based on those metrics.\nLet’s install the kube-prometheus-stack helm chart by copying the below-mentioned commands to your terminal. This will setup Grafana, Prometheus and other monitoring components.\n# Add and update the prometheus-community helm repository. helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo update cat \u003c","wordCount":"1506","inLanguage":"en","datePublished":"2023-01-30T00:00:00Z","dateModified":"2023-01-30T00:00:00Z","author":{"@type":"Person","name":"Tanmay Bhat"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://tanmay-bhat.github.io/posts/slo-based-alert-on-ingress-nginx/"},"publisher":{"@type":"Organization","name":"Tanmay Bhat","logo":{"@type":"ImageObject","url":"https://tanmay-bhat.github.io/memoji.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://tanmay-bhat.github.io accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://tanmay-bhat.github.io/about/ title=About><span>About</span></a></li><li><a href=https://tanmay-bhat.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://tanmay-bhat.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://tanmay-bhat.github.io>Home</a>&nbsp;»&nbsp;<a href=https://tanmay-bhat.github.io/posts/>Posts</a></div><h1 class=post-title>How to Configure Alerting on Ingress-NGINX in Kubernetes</h1><div class=post-meta><span title='2023-01-30 00:00:00 +0000 UTC'>January 30, 2023</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Tanmay Bhat&nbsp;|&nbsp;<a href=https://github.com/tanmay-bhat/tanmay-bhat.github.io/blob/main/content/posts/slo-based-alert-on-ingress-nginx.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>In this blog post, we will be discussing how to set up monitoring and alerting for Nginx ingress in a Kubernetes environment.</p><p>We will cover the installation and configuration of ingress-nginx, Prometheus and Grafana, and the setup of alerts for key Ingress metrics.</p><h3 id=pre-requisites->Pre-requisites :<a hidden class=anchor aria-hidden=true href=#pre-requisites->#</a></h3><ul><li>A Kubernetes cluster</li><li>Helm v3</li></ul><h2 id=install-prometheus-and-grafana>Install Prometheus and Grafana<a hidden class=anchor aria-hidden=true href=#install-prometheus-and-grafana>#</a></h2><p>In this step, we will install Prometheus to collect metrics, and Grafana to visualize and create alerts based on those metrics.</p><p>Let&rsquo;s install the <strong><a href=https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack>kube-prometheus-stack</a></strong> helm chart by copying the below-mentioned commands to your terminal. This will setup Grafana, Prometheus and other monitoring components.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Add and update the prometheus-community helm repository.</span>
</span></span><span style=display:flex><span>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
</span></span><span style=display:flex><span>helm repo update
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cat <span style=color:#e6db74>&lt;&lt;EOF | helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
</span></span></span><span style=display:flex><span><span style=color:#e6db74>--create-namespace -n monitoring -f -
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>grafana:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  adminPassword: &#34;admin&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  persistence:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    accessModes: [&#34;ReadWriteOnce&#34;]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    size: 1Gi
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  ingress:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    enabled: true
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    ingressClassName: nginx
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    hosts:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      - grafana.localdev.me
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span>
</span></span></code></pre></div><p>Let&rsquo;s see if the installed components are up and running :</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get pods -n monitoring
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NAME                                                        READY   STATUS    RESTARTS        AGE
</span></span><span style=display:flex><span>kube-prometheus-stack-grafana-7bb55544c9-qwkrg              3/3     Running   <span style=color:#ae81ff>0</span>               3m38s
</span></span><span style=display:flex><span>prometheus-kube-prometheus-stack-prometheus-0               2/2     Running   <span style=color:#ae81ff>0</span>               3m14s
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><p>Looks great, let&rsquo;s proceed to the next section.</p><h3 id=install--configure-ingress-nginx>Install & Configure Ingress Nginx<a hidden class=anchor aria-hidden=true href=#install--configure-ingress-nginx>#</a></h3><p>In this step, we will install and configure Nginx ingress controller and enable metrics that can be scraped by Prometheus.</p><ol><li>Let&rsquo;s install <strong>ingress-nginx</strong> into our cluster using below command:</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>helm upgrade --install ingress-nginx ingress-nginx <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --repo https://kubernetes.github.io/ingress-nginx <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --namespace ingress-nginx --create-namespace <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --set controller.metrics.enabled<span style=color:#f92672>=</span>true <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --set controller.metrics.serviceMonitor.enabled<span style=color:#f92672>=</span>true <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --set controller.metrics.serviceMonitor.additionalLabels.release<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;kube-prometheus-stack&#34;</span>
</span></span></code></pre></div><p>Here we&rsquo;re specifying <code>serviceMonitor.additionalLabels</code> to be <code>release: kube-prometheus-stack</code> so that Prometheus can discover the service monitor and automatically scrape metrics from it.</p><ol start=2><li>Once the chart is installed, let’s deploy a sample app <strong>podinfo</strong> into <code>default</code> namespace.</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>helm install --wait podinfo --namespace default <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>oci://ghcr.io/stefanprodan/charts/podinfo
</span></span></code></pre></div><ol start=3><li>Now, create an ingress for the deployed <strong>podinfo</strong> deployment :</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cat <span style=color:#e6db74>&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style=display:flex><span><span style=color:#e6db74>apiVersion: networking.k8s.io/v1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>kind: Ingress
</span></span></span><span style=display:flex><span><span style=color:#e6db74>metadata:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  name: podinfo-ingress
</span></span></span><span style=display:flex><span><span style=color:#e6db74>spec:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  ingressClassName: nginx
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  rules :
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  - host: podinfo.localdev.me
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  defaultBackend:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    service:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      name: podinfo
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      port:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        number: 9898
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span>
</span></span></code></pre></div><p>Let’s understand a bit about the above ingress config :</p><ul><li>We’re using <code>ingress-nginx</code> as our ingress controller, hence the ingress class is defined as <code>nginx</code>.</li><li>In the above config, I’ve used the host address for my Ingress as <code>podinfo.localdev.me</code>.</li><li>The DNS <code>*.localdev.me</code> resolves to <code>127.0.0.1</code>, hence for any local testing this DNS can be used without the hassle of adding an entry into <code>/etc/hosts</code> file.</li><li>Podinfo app serves HTTP API over port <code>9898</code>, hence it&rsquo;s specified for the backend port i.e. when the traffic arrives for the domain <code>http://podinfo.localdev.me</code>, it will be forwarded to <code>9898</code> of podinfo service.</li></ul><ol start=4><li>Next, from your terminal, port-forward the <code>ingress-nginx</code> service so that you can send traffic from your local terminal.</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl port-forward -n ingress-nginx service/ingress-nginx-controller 8080:80  &gt; /dev/null &amp;
</span></span></code></pre></div><ul><li>Port <code>80</code> on the host is a privileged port, so we’re not using that, instead we’re binding port <code>80</code> of nginx service to <code>8080</code> of host machine. You can specify any valid port of your choice.</li></ul><p>Note: If you’re running this in any cloud, port-forwarding is not required as LoadBalancer for <strong>ingress-nginx</strong> service will be auto-created since the service type is defined as <code>LoadBalancer</code> by default.</p><ol start=5><li>Now, you can run the below curl request to the podinfo endpoint, which should respond with :</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>&gt; curl http://podinfo.localdev.me:8080
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#e6db74>&#34;hostname&#34;</span>: <span style=color:#e6db74>&#34;podinfo-59cd496d88-8dcsx&#34;</span>
</span></span><span style=display:flex><span><span style=color:#e6db74>&#34;message&#34;</span>: <span style=color:#e6db74>&#34;greetings from podinfo v6.2.2&#34;</span>
</span></span></code></pre></div><ol start=6><li>You can also get the prettier look in the browser with URL : <a href=http://podinfo.localdev.me:8080/>http://podinfo.localdev.me:8080/</a></li></ol><p><img loading=lazy src=/podinfo-web.png alt="Podinfo web look"></p><h2 id=configure-grafana-dashboards-for-ingress-nginx-monitoring>Configure Grafana Dashboards for Ingress Nginx Monitoring<a hidden class=anchor aria-hidden=true href=#configure-grafana-dashboards-for-ingress-nginx-monitoring>#</a></h2><p>To access Grafana, you can open the below URL in your browser with the credential <code>admin:admin</code> : <a href=http://grafana.localdev.me:8080/>http://grafana.localdev.me:8080/</a>.</p><p>Copy the<code>nginx.json</code> from <a href=https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/grafana/dashboards/nginx.json>here</a> and paste it into <a href=http://grafana.localdev.me:8080/dashboard/import>http://grafana.localdev.me:8080/dashboard/import</a> to import the dashboard.</p><p>Once imported the dashboard should look like this :</p><p><img loading=lazy src=/nginx-ingress-dashboard.png alt="ingress-nginx Grafana dashboard"></p><h2 id=alerting-over-sli-metrics>Alerting over SLI metrics<a hidden class=anchor aria-hidden=true href=#alerting-over-sli-metrics>#</a></h2><p>Now that we have the dashboard and metrics ready in our Grafana, it’s time to set alerting on important SLI like Error Rate & Latency.</p><h3 id=generate-sample-loads>Generate sample loads<a hidden class=anchor aria-hidden=true href=#generate-sample-loads>#</a></h3><p>Inorder to get traffic on our my podinfo application, we’ll be using <a href=https://github.com/tsenart/vegeta>vegeta</a> as a loadtesting tool. Please install it from <a href=https://github.com/tsenart/vegeta>here</a>.</p><p>Let&rsquo;s generate a sample HTTP 4xx traffic. To do that, you can run the below command which will run at a request rate of 10 RPS for 10 minutes.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>echo <span style=color:#e6db74>&#34;GET http://podinfo.localdev.me:8080/status/400&#34;</span> | vegeta attack -duration<span style=color:#f92672>=</span>10m -rate<span style=color:#f92672>=</span>10/s
</span></span></code></pre></div><ul><li>You can just change the status code from 400 to 500 and run as well for test 5xx throughput.</li></ul><p>For latency tests, I’ve used the below command as <code>GET /delay/{seconds} waits for the specified period</code> :</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>echo <span style=color:#e6db74>&#34;GET http://podinfo.localdev.me:8080/delay/3&#34;</span> | vegeta attack -duration<span style=color:#f92672>=</span>10m -rate<span style=color:#f92672>=</span>100/s
</span></span></code></pre></div><p>Note: You can read more on the endpoints available in podinfo app from <a href=https://github.com/stefanprodan/podinfo>here</a>.</p><h3 id=grafana-alerting>Grafana Alerting<a hidden class=anchor aria-hidden=true href=#grafana-alerting>#</a></h3><p>The newer Grafana comes with its own alerting engine. That helps in keeping all config, rules and even firing alertsin one place. Let&rsquo;s configure alerts for common SLI.</p><h3 id=4xx-error-rate>4xx Error Rate<a hidden class=anchor aria-hidden=true href=#4xx-error-rate>#</a></h3><ol><li>Let&rsquo;s create an alert by going to <a href=http://grafana.localdev.me:8080/alerting/new>http://grafana.localdev.me:8080/alerting/new</a></li><li>We can use the following formula to get 4xx error rate percentage :</li></ol><p><code>(total number of 4xx requests / total number of requests) * 100</code></p><ol start=3><li>Add the below expression for the query :</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>(</span>sum<span style=color:#f92672>(</span>rate<span style=color:#f92672>(</span>nginx_ingress_controller_requests<span style=color:#f92672>{</span>status<span style=color:#f92672>=</span>~<span style=color:#e6db74>&#39;4..&#39;</span><span style=color:#f92672>}[</span>1m<span style=color:#f92672>]))</span> by <span style=color:#f92672>(</span>ingress<span style=color:#f92672>)</span> / sum<span style=color:#f92672>(</span>rate<span style=color:#f92672>(</span>nginx_ingress_controller_requests<span style=color:#f92672>[</span>1m<span style=color:#f92672>]))</span> by <span style=color:#f92672>(</span>ingress<span style=color:#f92672>))</span> * <span style=color:#ae81ff>100</span> &gt; <span style=color:#ae81ff>5</span>
</span></span></code></pre></div><ol start=4><li>In Expression <code>B</code>, use <code>Reduce</code> operation with the function <code>Mean</code> for input <code>A</code>.</li></ol><p><img loading=lazy src=/nginx-ingress-alert-config.png alt="ingress-nginx grafana alerting config"></p><ol start=5><li>In Alert Details, Name the alert as per your liking, I’ve named it <code>Ingress_Nginx_4xx</code>.</li><li>For Summary, we can keep it as short as possible, by just displaying the Ingress name with label <code>{{ $labels.ingress }}</code>.</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#a6e22e>Ingress</span> <span style=color:#a6e22e>High</span> <span style=color:#a6e22e>Error</span> <span style=color:#a6e22e>Rate</span> : <span style=color:#ae81ff>4</span><span style=color:#a6e22e>xx</span> <span style=color:#a6e22e>on</span> <span style=color:#f92672>*</span>{{ <span style=color:#960050;background-color:#1e0010>$</span><span style=color:#a6e22e>labels</span>.<span style=color:#a6e22e>ingress</span> }}<span style=color:#f92672>*</span>
</span></span></code></pre></div><ol start=7><li>For Description, I’ve used <code>printf "%0.2f"</code> to display upto two decimals on the percentage value.</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#ae81ff>4</span><span style=color:#a6e22e>xx</span> : <span style=color:#a6e22e>High</span> <span style=color:#a6e22e>Error</span> <span style=color:#a6e22e>rate</span> : <span style=color:#e6db74>`</span><span style=color:#75715e>{{</span> <span style=color:#66d9ef>printf</span> <span style=color:#e6db74>&#34;%0.2f&#34;</span> <span style=color:#a6e22e>$values</span><span style=color:#a6e22e>.B.Value</span> <span style=color:#75715e>}}</span><span style=color:#e6db74>%`</span> <span style=color:#a6e22e>on</span> <span style=color:#f92672>*</span>{{ <span style=color:#960050;background-color:#1e0010>$</span><span style=color:#a6e22e>labels</span>.<span style=color:#a6e22e>ingress</span> }}<span style=color:#f92672>*</span>.
</span></span></code></pre></div><ol start=8><li>Overall alert should look similar to the below snapshot :</li></ol><p><img loading=lazy src=/nginx-ingress-alert-details.png alt="ingress-nginx grafana alert details"></p><ol start=9><li>In the end, you can add a custom label like <code>severity : critical</code>.</li></ol><h3 id=5xx-error-rate>5xx Error Rate<a hidden class=anchor aria-hidden=true href=#5xx-error-rate>#</a></h3><p>Similar to 4xx alert config, 5xx error rate can also be queried with the below query :</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#a6e22e>sum</span>(<span style=color:#a6e22e>rate</span>(<span style=color:#a6e22e>nginx_ingress_controller_requests</span>{<span style=color:#a6e22e>status</span>=<span style=color:#960050;background-color:#1e0010>~&#39;</span><span style=color:#ae81ff>5.</span>.<span style=color:#960050;background-color:#1e0010>&#39;</span>}[<span style=color:#ae81ff>1</span><span style=color:#a6e22e>m</span>])) <span style=color:#a6e22e>by</span> (<span style=color:#a6e22e>ingress</span>,<span style=color:#a6e22e>cluster</span>) <span style=color:#f92672>/</span> <span style=color:#a6e22e>sum</span>(<span style=color:#a6e22e>rate</span>(<span style=color:#a6e22e>nginx_ingress_controller_requests</span>[<span style=color:#ae81ff>1</span><span style=color:#a6e22e>m</span>]))<span style=color:#a6e22e>by</span> (<span style=color:#a6e22e>ingress</span>) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span> &gt; <span style=color:#ae81ff>5</span>
</span></span></code></pre></div><p>Note: I’ve configured the alert to be triggered then the 5xx/4xx percentage is > 5%. You can set it as per your error budget.</p><h3 id=high-latency-p95>High Latency (p95)<a hidden class=anchor aria-hidden=true href=#high-latency-p95>#</a></h3><p>To calculate the 95th percentile of request durations over the last 15m we can use the <code>nginx_ingress_controller_request_duration_seconds_bucket</code> metric.</p><p>It gives you <strong>The request processing time in milliseconds</strong> and since its a bucket we can use <code>histogram_quantile</code> function.</p><p>Similarly create a alert to above examples and use the below query :</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#a6e22e>histogram_quantile</span>(<span style=color:#ae81ff>0.95</span>,<span style=color:#a6e22e>sum</span>(<span style=color:#a6e22e>rate</span>(<span style=color:#a6e22e>nginx_ingress_controller_request_duration_seconds_bucket</span>[<span style=color:#ae81ff>15</span><span style=color:#a6e22e>m</span>])) <span style=color:#a6e22e>by</span> (<span style=color:#a6e22e>le</span>,<span style=color:#a6e22e>ingress</span>)) &gt; <span style=color:#ae81ff>1.5</span>
</span></span></code></pre></div><p>I’ve set the threshold to 1.5 seconds, it can be updated as per your SLO.</p><h3 id=high-request-rate>High Request rate<a hidden class=anchor aria-hidden=true href=#high-request-rate>#</a></h3><p>To get the request rate per second (RPS), we can use the below query :</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#a6e22e>sum</span>(<span style=color:#a6e22e>rate</span>(<span style=color:#a6e22e>nginx_ingress_controller_requests</span>[<span style=color:#ae81ff>5</span><span style=color:#a6e22e>m</span>])) <span style=color:#a6e22e>by</span> (<span style=color:#a6e22e>ingress</span>) &gt; <span style=color:#ae81ff>2000</span>
</span></span></code></pre></div><p>The above query will trigger an alert when the request rate is greater than 2000 RPS.</p><h3 id=other-slis-to-consider>Other SLIs to consider<a hidden class=anchor aria-hidden=true href=#other-slis-to-consider>#</a></h3><p><strong>Connection rate</strong>: This measures the number of active connections to Nginx ingress, and can be used to identify potential issues with connection handling.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>rate<span style=color:#f92672>(</span>nginx_ingress_controller_nginx_process_connections<span style=color:#f92672>{</span>ingress<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;ingress-name&#34;</span><span style=color:#f92672>}[</span>5m<span style=color:#f92672>])</span>
</span></span></code></pre></div><p><strong>Upstream response time</strong>: The time it takes for the underlying service to respond to a request, this will help to identify issues with the service and not just the ingress.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>histogram_quantile<span style=color:#f92672>(</span>0.95,sum<span style=color:#f92672>(</span>rate<span style=color:#f92672>(</span>nginx_ingress_controller_response_duration_seconds_bucket<span style=color:#f92672>[</span>15m<span style=color:#f92672>]))</span> by <span style=color:#f92672>(</span>le,ingress<span style=color:#f92672>))</span> 
</span></span></code></pre></div><h3 id=slack-alert-template>Slack Alert Template<a hidden class=anchor aria-hidden=true href=#slack-alert-template>#</a></h3><p>To make alert messages meaningful, we can use <a href=https://grafana.com/docs/grafana/latest/alerting/contact-points/message-templating/>alert templates in Grafana.</a></p><ol><li>In order to configure them, go to <a href=http://grafana.localdev.me:8080/alerting/notifications>http://grafana.localdev.me:8080/alerting/notifications</a> and create a new template named <code>slack</code> by pasting the below code block :</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span>{{ <span style=color:#a6e22e>define</span> <span style=color:#e6db74>&#34;alert_severity_prefix_emoji&#34;</span> <span style=color:#f92672>-</span>}}
</span></span><span style=display:flex><span>	{{<span style=color:#f92672>-</span> <span style=color:#66d9ef>if</span> <span style=color:#a6e22e>ne</span> .<span style=color:#a6e22e>Status</span> <span style=color:#e6db74>&#34;firing&#34;</span> <span style=color:#f92672>-</span>}}
</span></span><span style=display:flex><span>		<span style=color:#960050;background-color:#1e0010>✅</span>
</span></span><span style=display:flex><span>	{{<span style=color:#f92672>-</span> <span style=color:#66d9ef>else</span> <span style=color:#66d9ef>if</span> <span style=color:#a6e22e>eq</span> .<span style=color:#a6e22e>CommonLabels</span>.<span style=color:#a6e22e>severity</span> <span style=color:#e6db74>&#34;critical&#34;</span> <span style=color:#f92672>-</span>}}
</span></span><span style=display:flex><span>		<span style=color:#960050;background-color:#1e0010>🔥</span>
</span></span><span style=display:flex><span>	{{<span style=color:#f92672>-</span> <span style=color:#66d9ef>else</span> <span style=color:#66d9ef>if</span> <span style=color:#a6e22e>eq</span> .<span style=color:#a6e22e>CommonLabels</span>.<span style=color:#a6e22e>severity</span> <span style=color:#e6db74>&#34;warning&#34;</span> <span style=color:#f92672>-</span>}}
</span></span><span style=display:flex><span>		<span style=color:#960050;background-color:#1e0010>⚠️</span>
</span></span><span style=display:flex><span>	{{<span style=color:#f92672>-</span> <span style=color:#a6e22e>end</span> <span style=color:#f92672>-</span>}}
</span></span><span style=display:flex><span>{{<span style=color:#f92672>-</span> <span style=color:#a6e22e>end</span> <span style=color:#f92672>-</span>}}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>{{ <span style=color:#a6e22e>define</span> <span style=color:#e6db74>&#34;slack.title&#34;</span> <span style=color:#f92672>-</span>}}
</span></span><span style=display:flex><span>	{{ <span style=color:#a6e22e>template</span> <span style=color:#e6db74>&#34;alert_severity_prefix_emoji&#34;</span> . }}  {{<span style=color:#f92672>-</span> .<span style=color:#a6e22e>Status</span> | <span style=color:#a6e22e>toUpper</span> <span style=color:#f92672>-</span>}}{{<span style=color:#f92672>-</span> <span style=color:#66d9ef>if</span> <span style=color:#a6e22e>eq</span> .<span style=color:#a6e22e>Status</span> <span style=color:#e6db74>&#34;firing&#34;</span> }} <span style=color:#a6e22e>x</span> {{ .<span style=color:#a6e22e>Alerts</span>.<span style=color:#a6e22e>Firing</span> | <span style=color:#a6e22e>len</span> <span style=color:#f92672>-</span>}}{{<span style=color:#f92672>-</span> <span style=color:#a6e22e>end</span> }}  |  {{ .<span style=color:#a6e22e>CommonLabels</span>.<span style=color:#a6e22e>alertname</span> <span style=color:#f92672>-</span>}}
</span></span><span style=display:flex><span>{{<span style=color:#f92672>-</span> <span style=color:#a6e22e>end</span> <span style=color:#f92672>-</span>}}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>{{<span style=color:#f92672>-</span> <span style=color:#a6e22e>define</span> <span style=color:#e6db74>&#34;slack.text&#34;</span> <span style=color:#f92672>-</span>}}
</span></span><span style=display:flex><span>{{<span style=color:#f92672>-</span> <span style=color:#66d9ef>range</span> .<span style=color:#a6e22e>Alerts</span> <span style=color:#f92672>-</span>}}
</span></span><span style=display:flex><span>{{ <span style=color:#66d9ef>if</span> <span style=color:#a6e22e>gt</span> (<span style=color:#a6e22e>len</span> .<span style=color:#a6e22e>Annotations</span>) <span style=color:#ae81ff>0</span> }}
</span></span><span style=display:flex><span><span style=color:#f92672>*</span><span style=color:#a6e22e>Summary</span><span style=color:#f92672>*</span>: {{ .<span style=color:#a6e22e>Annotations</span>.<span style=color:#a6e22e>summary</span>}}
</span></span><span style=display:flex><span><span style=color:#f92672>*</span><span style=color:#a6e22e>Description</span><span style=color:#f92672>*</span>: {{ .<span style=color:#a6e22e>Annotations</span>.<span style=color:#a6e22e>description</span> }}
</span></span><span style=display:flex><span><span style=color:#a6e22e>Labels</span>: 
</span></span><span style=display:flex><span>{{ <span style=color:#66d9ef>range</span> .<span style=color:#a6e22e>Labels</span>.<span style=color:#a6e22e>SortedPairs</span> }}{{ <span style=color:#66d9ef>if</span> <span style=color:#a6e22e>or</span> (<span style=color:#a6e22e>eq</span> .<span style=color:#a6e22e>Name</span> <span style=color:#e6db74>&#34;ingress&#34;</span>) (<span style=color:#a6e22e>eq</span> .<span style=color:#a6e22e>Name</span> <span style=color:#e6db74>&#34;cluster&#34;</span>) }}<span style=color:#960050;background-color:#1e0010>•</span> {{ .<span style=color:#a6e22e>Name</span> }}: <span style=color:#e6db74>`</span><span style=color:#75715e>{{</span> <span style=color:#a6e22e>.Value</span> <span style=color:#75715e>}}</span><span style=color:#e6db74>`</span>
</span></span><span style=display:flex><span>{{ <span style=color:#a6e22e>end</span> }}{{ <span style=color:#a6e22e>end</span> }}
</span></span><span style=display:flex><span>{{ <span style=color:#a6e22e>end</span> }}
</span></span><span style=display:flex><span>{{ <span style=color:#a6e22e>end</span> }}
</span></span><span style=display:flex><span>{{ <span style=color:#a6e22e>end</span> }}
</span></span></code></pre></div><ol start=2><li><p>Configure a new contact point of type Slack. For this, you need to create an incoming webhook from Slack. Refer <a href=https://api.slack.com/messaging/webhooks#create_a_webhook>this doc</a> for more detailed steps.</p></li><li><p>Edit the contact point <strong>slack</strong> and scroll down and select the option <strong><code>Optional Slack settings</code>.</strong></p></li><li><p>In the <strong>Title,</strong> enter the below to specify the template to use:</p></li></ol><pre tabindex=0><code>{{ template &#34;slack.title&#34; . }}
</code></pre><ol start=5><li>In the <strong>Text Body,</strong> enter the below and save it :</li></ol><pre tabindex=0><code>{{ template &#34;slack.text&#34; . }}
</code></pre><ol start=6><li>Go to <a href=http://grafana.localdev.me:8080/alerting/routes>http://grafana.localdev.me:8080/alerting/routes</a> and configure the <strong>Default contact point</strong> to be <strong>Slack</strong>.</li></ol><h3 id=finally-the-alert-message-arrives>Finally, the alert message arrives!<a hidden class=anchor aria-hidden=true href=#finally-the-alert-message-arrives>#</a></h3><p>After configuring all the steps, finally we arrive at the end and below are the snapshots of how the alert will look on your slack.</p><p>4xx Error Rate :</p><p><img loading=lazy src=/4xx-slack-alert.png alt="4xx slack alert"></p><p>5xx Error Rate :</p><p><img loading=lazy src=/5xx-slack-alert.png alt="5xx slack alert"></p><p>Latency P95 :</p><p><img loading=lazy src=/p65-slack-alert.png alt="p95 slack alert"></p><p>There are lots of things one can improve according to their requirements. For example, if you have mulltple Kubernetes clusters, you can add a <code>cluster</code> label which will help in identifying the source cluster for the alert.</p><hr><h3 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h3><p><a href=https://grafana.com/docs/grafana/latest/alerting/>https://grafana.com/docs/grafana/latest/alerting/</a></p><p><a href=https://kubernetes.github.io/ingress-nginx/user-guide/monitoring/>https://kubernetes.github.io/ingress-nginx/user-guide/monitoring/</a></p><p><a href=https://github.com/stefanprodan/podinfo>https://github.com/stefanprodan/podinfo</a></p><hr></div><footer class=post-footer><ul class=post-tags><li><a href=https://tanmay-bhat.github.io/tags/ingress/>ingress</a></li><li><a href=https://tanmay-bhat.github.io/tags/kubernetes/>Kubernetes</a></li><li><a href=https://tanmay-bhat.github.io/tags/prometheus/>Prometheus</a></li></ul><nav class=paginav><a class=prev href=https://tanmay-bhat.github.io/posts/syslog-parsing-with-fluentd/><span class=title>« Prev</span><br><span>An Overview of Syslog Parsing with Fluentd</span></a>
<a class=next href=https://tanmay-bhat.github.io/posts/helm-chart-testing-github-actions/><span class=title>Next »</span><br><span>Automate Your Helm Chart Testing Workflow with GitHub Actions</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share How to Configure Alerting on Ingress-NGINX in Kubernetes on twitter" href="https://twitter.com/intent/tweet/?text=How%20to%20Configure%20Alerting%20on%20Ingress-NGINX%20in%20Kubernetes&amp;url=https%3a%2f%2ftanmay-bhat.github.io%2fposts%2fslo-based-alert-on-ingress-nginx%2f&amp;hashtags=ingress%2ckubernetes%2cprometheus"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share How to Configure Alerting on Ingress-NGINX in Kubernetes on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2ftanmay-bhat.github.io%2fposts%2fslo-based-alert-on-ingress-nginx%2f&amp;title=How%20to%20Configure%20Alerting%20on%20Ingress-NGINX%20in%20Kubernetes&amp;summary=How%20to%20Configure%20Alerting%20on%20Ingress-NGINX%20in%20Kubernetes&amp;source=https%3a%2f%2ftanmay-bhat.github.io%2fposts%2fslo-based-alert-on-ingress-nginx%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share How to Configure Alerting on Ingress-NGINX in Kubernetes on reddit" href="https://reddit.com/submit?url=https%3a%2f%2ftanmay-bhat.github.io%2fposts%2fslo-based-alert-on-ingress-nginx%2f&title=How%20to%20Configure%20Alerting%20on%20Ingress-NGINX%20in%20Kubernetes"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share How to Configure Alerting on Ingress-NGINX in Kubernetes on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ftanmay-bhat.github.io%2fposts%2fslo-based-alert-on-ingress-nginx%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share How to Configure Alerting on Ingress-NGINX in Kubernetes on whatsapp" href="https://api.whatsapp.com/send?text=How%20to%20Configure%20Alerting%20on%20Ingress-NGINX%20in%20Kubernetes%20-%20https%3a%2f%2ftanmay-bhat.github.io%2fposts%2fslo-based-alert-on-ingress-nginx%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share How to Configure Alerting on Ingress-NGINX in Kubernetes on telegram" href="https://telegram.me/share/url?text=How%20to%20Configure%20Alerting%20on%20Ingress-NGINX%20in%20Kubernetes&amp;url=https%3a%2f%2ftanmay-bhat.github.io%2fposts%2fslo-based-alert-on-ingress-nginx%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://tanmay-bhat.github.io>Tanmay Bhat</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>