<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Self monitoring Prometheus with Grafana | Tanmay Bhat</title>
<meta name=keywords content="Prometheus,Grafana"><meta name=description content="Who will monitor the monitoring system ? Itself&mldr;&mldr;&mldr;sounds a bit magical.
Since Prometheus monitors everything, it&rsquo;s essential that we keep an eye on Prometheus so that over observability pillar stays strong.
If Prometheus goes down, you won&rsquo;t be having any metrics, hence no alert for any services, scary stuff along with a call from your boss !!
Configuring Prometheus to monitor itself
Prometheus exposes metrics about itself  at /metrics endpoint, hence it can scrape and monitor its own health."><meta name=author content="Tanmay Bhat"><link rel=canonical href=https://tanmay-bhat.github.io/posts/prometheus-self-metrics/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as=style><link rel=icon href=https://tanmay-bhat.github.io/memoji.png><link rel=icon type=image/png sizes=16x16 href=https://tanmay-bhat.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://tanmay-bhat.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://tanmay-bhat.github.io/apple-touch-icon.png><link rel=mask-icon href=https://tanmay-bhat.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://tanmay-bhat.github.io/posts/prometheus-self-metrics/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-6PXF78BGMY"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6PXF78BGMY")}</script><meta property="og:url" content="https://tanmay-bhat.github.io/posts/prometheus-self-metrics/"><meta property="og:site_name" content="Tanmay Bhat"><meta property="og:title" content="Self monitoring Prometheus with Grafana"><meta property="og:description" content="Who will monitor the monitoring system ? Itself………sounds a bit magical.
Since Prometheus monitors everything, it’s essential that we keep an eye on Prometheus so that over observability pillar stays strong.
If Prometheus goes down, you won’t be having any metrics, hence no alert for any services, scary stuff along with a call from your boss !!
Configuring Prometheus to monitor itself Prometheus exposes metrics about itself at /metrics endpoint, hence it can scrape and monitor its own health."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-03-14T00:00:00+00:00"><meta property="article:modified_time" content="2022-03-14T00:00:00+00:00"><meta property="article:tag" content="Prometheus"><meta property="article:tag" content="Grafana"><meta property="og:image" content="https://tanmay-bhat.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://tanmay-bhat.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Self monitoring Prometheus with Grafana"><meta name=twitter:description content="Who will monitor the monitoring system ? Itself&mldr;&mldr;&mldr;sounds a bit magical.
Since Prometheus monitors everything, it&rsquo;s essential that we keep an eye on Prometheus so that over observability pillar stays strong.
If Prometheus goes down, you won&rsquo;t be having any metrics, hence no alert for any services, scary stuff along with a call from your boss !!
Configuring Prometheus to monitor itself
Prometheus exposes metrics about itself  at /metrics endpoint, hence it can scrape and monitor its own health."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://tanmay-bhat.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Self monitoring Prometheus with Grafana","item":"https://tanmay-bhat.github.io/posts/prometheus-self-metrics/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Self monitoring Prometheus with Grafana","name":"Self monitoring Prometheus with Grafana","description":"Who will monitor the monitoring system ? Itself\u0026hellip;\u0026hellip;\u0026hellip;sounds a bit magical.\nSince Prometheus monitors everything, it\u0026rsquo;s essential that we keep an eye on Prometheus so that over observability pillar stays strong.\nIf Prometheus goes down, you won\u0026rsquo;t be having any metrics, hence no alert for any services, scary stuff along with a call from your boss !!\nConfiguring Prometheus to monitor itself Prometheus exposes metrics about itself at /metrics endpoint, hence it can scrape and monitor its own health.\n","keywords":["Prometheus","Grafana"],"articleBody":"Who will monitor the monitoring system ? Itself………sounds a bit magical.\nSince Prometheus monitors everything, it’s essential that we keep an eye on Prometheus so that over observability pillar stays strong.\nIf Prometheus goes down, you won’t be having any metrics, hence no alert for any services, scary stuff along with a call from your boss !!\nConfiguring Prometheus to monitor itself Prometheus exposes metrics about itself at /metrics endpoint, hence it can scrape and monitor its own health.\nAdd a Prometheus scrape job in prometheus.yml config file : scrape_configs: - job_name: prometheus static_configs: - targets: - localhost:9090 # prometheus endpoint address Restart the Prometheus \u0026 curl the /metrics endpoint of Prometheus server to verify: curl http://localhost:1256/metrics # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 7.3633e-05 go_gc_duration_seconds{quantile=\"0.25\"} 9.2295e-05 go_gc_duration_seconds{quantile=\"0.5\"} 0.000100231 go_gc_duration_seconds{quantile=\"0.75\"} 0.000110334 go_gc_duration_seconds{quantile=\"1\"} 0.001204485 go_gc_duration_seconds_sum 43.914716791000004 go_gc_duration_seconds_count 191769 Looks good, let’s move ahead.\nTime Series Prometheus fundamentally stores all data as time series streams of timestamped values belonging to the same metric and the same set of labeled dimensions.\nUnderstanding valuable metrics 1. Active time Series count : prometheus_tsdb_head_series metric type : Gauge\nThis metric shows total number of active time series in the head block. A time series is considered active if new data points have been generated within the last 15 to 30 minutes. A head block in TSDB is an in-memory part of database where time series are stored for a shorter period and then later flushed to persistent disk storage. Read more about how head block works in Prometheus TSDB here. Total Available series in head block can be calculated using the below expression : max_over_time(prometheus_tsdb_head_series[1d]) 2. Time Series Created : prometheus_tsdb_head_series_created_total metric type: Counter\nThis metrics displays total number of time series created in the head block. Since it’s a counter, we can calculate its rate with expression : rate(prometheus_tsdb_head_series_created_total[5m]) 3. Time Series Deleted : prometheus_tsdb_head_series_removed_total metric type: Counter\nThis metrics displays total number of time series removed in the head block. To calculate, rate of deletion of time series with per second average, you can run : rate(prometheus_tsdb_head_series_removed_total[5m]) As you can see from the above graph, the time series are removed from the head and are flushed to persistent storage around every 2 hours. Samples: A sample is a combination of timestamp, value of a time series metric. For example, memory used by container A at time 1:50 \u0026 1:51. These are two samples for the same metric or same time series. 4. Samples ingested : prometheus_tsdb_head_samples_appended_total metric type: Counter\nThis metric shows total number of appended samples into the head block. This metrics is different from the metric scrape_samples_scraped because the appended metric shows the number of samples added / ingested into head block, whereas samples_scraped shows how many samples were scraped. The difference comes into play when you are dropping a lot of metrics via relabel config in your Prometheus config. Sample ingestion rate can be calculated with the expression : rate(prometheus_tsdb_head_samples_appended_total[5m]) 5. Sample size : metric type: Gauge\nThe below expression will give the size of the sample ingested by the Prometheus. In an ideal scenario, the size of each sample will be around 1-2 byte. Sample size monitoring is essential because if there’s anomaly and size goes beyond 3-4 byte, Storage of the server will wear out quickly, leading to disaster. Size of sample can be calculated using the below : (rate(prometheus_tsdb_compaction_chunk_size_bytes_sum[1d])) / rate(prometheus_tsdb_compaction_chunk_samples_sum[1d]) 3. Samples scraped per job : scrape_samples_scraped metric type: Counter\nOver time, you might need to keep an eye on which job is contributing to the highest samples getting scraped and ingested. For that, the above metric comes to the rescue. In an easier way, this metric displays how many metrics are scraped by a job. Hence, you can write a promQL expression to configure an alert too if it breaches a certain threshold. Total samples scraped / job can be calculated by using the below expression : sum by (job)(scrape_samples_scraped) 3. Scrape duration : prometheus_target_interval_length_seconds metric type: Gauge\nYou might also need to monitor the scrape duration heath of your Prometheus. If the duration goes beyond a certain threshold value, the samples will get out of order. More details \u0026 debugging out of order samples here. P99 of the scrape duration can be calculated using the below expression :\nprometheus_target_interval_length_seconds{quantile=\"0.9\"} I’ve listed above some important metrics you can look for, there’s lot more of them at /metrics endpoint of your Prometheus server.\nGrafana Dashboard For quicker insights, I’ve made a Grafana dashboard from all the above expressions mentioned.\nWhich looks like this :\nYou can import the JSON file from here to your Grafana instance to get started.\nReferences : https://www.omerlh.info/2019/03/04/keeping-prometheus-in-shape/\nhttps://prometheus.io/docs/prometheus/latest/getting_started/#configuring-prometheus-to-monitor-itself\nhttps://ganeshvernekar.com/blog/prometheus-tsdb-the-head-block/\n","wordCount":"788","inLanguage":"en","image":"https://tanmay-bhat.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2022-03-14T00:00:00Z","dateModified":"2022-03-14T00:00:00Z","author":{"@type":"Person","name":"Tanmay Bhat"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://tanmay-bhat.github.io/posts/prometheus-self-metrics/"},"publisher":{"@type":"Organization","name":"Tanmay Bhat","logo":{"@type":"ImageObject","url":"https://tanmay-bhat.github.io/memoji.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://tanmay-bhat.github.io/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://tanmay-bhat.github.io/about/ title=About><span>About</span></a></li><li><a href=https://tanmay-bhat.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://tanmay-bhat.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://tanmay-bhat.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://tanmay-bhat.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Self monitoring Prometheus with Grafana</h1><div class=post-meta><span title='2022-03-14 00:00:00 +0000 UTC'>March 14, 2022</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Tanmay Bhat&nbsp;|&nbsp;<a href=https://github.com/tanmay-bhat/tanmay-bhat.github.io/blob/main/content/posts/prometheus-self-metrics.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>Who will monitor the monitoring system ? <em>Itself</em>&mldr;&mldr;&mldr;sounds a bit magical.</p><p>Since Prometheus monitors everything, it&rsquo;s essential that we keep an eye on Prometheus so that over observability pillar stays strong.</p><p>If Prometheus goes down, you won&rsquo;t be having any metrics, hence no alert for any services, scary stuff along with a call from your boss !!</p><h3 id=configuring-prometheus-to-monitor-itself><strong><strong>Configuring Prometheus to monitor itself</strong></strong><a hidden class=anchor aria-hidden=true href=#configuring-prometheus-to-monitor-itself>#</a></h3><p>Prometheus exposes metrics about itself at <code>/metrics</code> endpoint, hence it can scrape and monitor its own health.</p><ol><li>Add a Prometheus scrape job in <code>prometheus.yml</code> config file :</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>scrape_configs:
</span></span><span style=display:flex><span>      - job_name: prometheus
</span></span><span style=display:flex><span>        static_configs:
</span></span><span style=display:flex><span>          - targets:
</span></span><span style=display:flex><span>            - localhost:9090 <span style=color:#75715e># prometheus endpoint address</span>
</span></span></code></pre></div><ol start=2><li>Restart the Prometheus & curl the <code>/metrics</code> endpoint of Prometheus server to verify:</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl http://localhost:1256/metrics
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># TYPE go_gc_duration_seconds summary</span>
</span></span><span style=display:flex><span>go_gc_duration_seconds<span style=color:#f92672>{</span>quantile<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;0&#34;</span><span style=color:#f92672>}</span> 7.3633e-05
</span></span><span style=display:flex><span>go_gc_duration_seconds<span style=color:#f92672>{</span>quantile<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;0.25&#34;</span><span style=color:#f92672>}</span> 9.2295e-05
</span></span><span style=display:flex><span>go_gc_duration_seconds<span style=color:#f92672>{</span>quantile<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;0.5&#34;</span><span style=color:#f92672>}</span> 0.000100231
</span></span><span style=display:flex><span>go_gc_duration_seconds<span style=color:#f92672>{</span>quantile<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;0.75&#34;</span><span style=color:#f92672>}</span> 0.000110334
</span></span><span style=display:flex><span>go_gc_duration_seconds<span style=color:#f92672>{</span>quantile<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;1&#34;</span><span style=color:#f92672>}</span> 0.001204485
</span></span><span style=display:flex><span>go_gc_duration_seconds_sum 43.914716791000004
</span></span><span style=display:flex><span>go_gc_duration_seconds_count <span style=color:#ae81ff>191769</span>
</span></span></code></pre></div><p>Looks good, let’s move ahead.</p><h3 id=time-series>Time Series<a hidden class=anchor aria-hidden=true href=#time-series>#</a></h3><blockquote><p>Prometheus fundamentally stores all data as <em><a href=https://en.wikipedia.org/wiki/Time_series>time series</a></em> streams of timestamped values belonging to the same metric and the same set of labeled dimensions.</p></blockquote><h2 id=understanding-valuable-metrics>Understanding valuable metrics<a hidden class=anchor aria-hidden=true href=#understanding-valuable-metrics>#</a></h2><h3 id=1-active-time-series-count--prometheus_tsdb_head_series>1. Active time Series count : <code>prometheus_tsdb_head_series</code><a hidden class=anchor aria-hidden=true href=#1-active-time-series-count--prometheus_tsdb_head_series>#</a></h3><p><em>metric type : Gauge</em></p><ul><li>This metric shows total number of active time series in the head block.</li><li>A time series is considered active if new data points have been generated within the last 15 to 30 minutes.</li><li>A head block in TSDB is an in-memory part of database where time series are stored for a shorter period and then later flushed to persistent disk storage.</li><li>Read more about how head block works in Prometheus TSDB <a href=https://ganeshvernekar.com/blog/prometheus-tsdb-the-head-block/>here</a>.</li><li>Total Available series in head block can be calculated using the below expression :</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span>max_over_time(prometheus_tsdb_head_series[<span style=color:#ae81ff>1</span>d])
</span></span></code></pre></div><p><img alt="total time series in head" loading=lazy src=/series-count.png></p><h3 id=2-time-series-created--prometheus_tsdb_head_series_created_total>2. Time Series Created : <code>prometheus_tsdb_head_series_created_total</code><a hidden class=anchor aria-hidden=true href=#2-time-series-created--prometheus_tsdb_head_series_created_total>#</a></h3><p><em>metric type: Counter</em></p><ul><li>This metrics displays total number of time series created in the head block.</li><li>Since it’s a counter, we can calculate its rate with expression :</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-jsx data-lang=jsx><span style=display:flex><span><span style=color:#a6e22e>rate</span>(<span style=color:#a6e22e>prometheus_tsdb_head_series_created_total</span>[<span style=color:#ae81ff>5</span><span style=color:#a6e22e>m</span>])
</span></span></code></pre></div><p><img alt="total series created in head" loading=lazy src=/series-created.png></p><h3 id=3-time-series-deleted--prometheus_tsdb_head_series_removed_total>3. Time Series Deleted : <code>prometheus_tsdb_head_series_removed_total</code><a hidden class=anchor aria-hidden=true href=#3-time-series-deleted--prometheus_tsdb_head_series_removed_total>#</a></h3><p><em>metric type: Counter</em></p><ul><li>This metrics displays total number of time series removed in the head block.</li><li>To calculate, rate of deletion of time series with per second average, you can run :</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-jsx data-lang=jsx><span style=display:flex><span><span style=color:#a6e22e>rate</span>(<span style=color:#a6e22e>prometheus_tsdb_head_series_removed_total</span>[<span style=color:#ae81ff>5</span><span style=color:#a6e22e>m</span>])
</span></span></code></pre></div><p><img alt="total series deleted in head" loading=lazy src=/series-deleted.png></p><ul><li>As you can see from the above graph, the time series are removed from the head and are flushed to persistent storage around every 2 hours.</li></ul><h2 id=samples>Samples:<a hidden class=anchor aria-hidden=true href=#samples>#</a></h2><ul><li>A sample is a combination of <code>timestamp, value</code> of a time series metric.</li><li>For example, memory used by container A at time 1:50 & 1:51. These are two samples for the same metric or same time series.</li></ul><h3 id=4-samples-ingested--prometheus_tsdb_head_samples_appended_total>4. Samples ingested : <code>prometheus_tsdb_head_samples_appended_total</code><a hidden class=anchor aria-hidden=true href=#4-samples-ingested--prometheus_tsdb_head_samples_appended_total>#</a></h3><p><em>metric type: Counter</em></p><ul><li>This metric shows total number of appended samples into the head block.</li><li>This metrics is different from the metric <code>scrape_samples_scraped</code> because the appended metric shows the number of samples added / ingested into head block, whereas samples_scraped shows how many samples were scraped. The difference comes into play when you are dropping a lot of metrics via relabel config in your Prometheus config.</li><li>Sample ingestion rate can be calculated with the expression :</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-jsx data-lang=jsx><span style=display:flex><span><span style=color:#a6e22e>rate</span>(<span style=color:#a6e22e>prometheus_tsdb_head_samples_appended_total</span>[<span style=color:#ae81ff>5</span><span style=color:#a6e22e>m</span>])
</span></span></code></pre></div><p><img alt="samples ingested" loading=lazy src=/sample-ingested.png></p><h3 id=5-sample-size->5. Sample size :<a hidden class=anchor aria-hidden=true href=#5-sample-size->#</a></h3><p><em>metric type: Gauge</em></p><ul><li>The below expression will give the size of the sample ingested by the Prometheus.</li><li>In an ideal scenario, the size of each sample will be around 1-2 byte.</li><li>Sample size monitoring is essential because if there’s anomaly and size goes beyond 3-4 byte, Storage of the server will wear out quickly, leading to disaster.</li><li>Size of sample can be calculated using the below :</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span>(rate(prometheus_tsdb_compaction_chunk_size_bytes_sum[<span style=color:#ae81ff>1</span>d])) <span style=color:#f92672>/</span> rate(prometheus_tsdb_compaction_chunk_samples_sum[<span style=color:#ae81ff>1</span>d])
</span></span></code></pre></div><p><img alt="samples size" loading=lazy src=/sample-size.png></p><h3 id=3-samples-scraped-per-job--scrape_samples_scraped>3. Samples scraped per job : <code>scrape_samples_scraped</code><a hidden class=anchor aria-hidden=true href=#3-samples-scraped-per-job--scrape_samples_scraped>#</a></h3><p><em>metric type: Counter</em></p><ul><li>Over time, you might need to keep an eye on which job is contributing to the highest samples getting scraped and ingested. For that, the above metric comes to the rescue.</li><li>In an easier way, this metric displays how many metrics are scraped by a job. Hence, you can write a promQL expression to configure an alert too if it breaches a certain threshold.</li><li>Total samples scraped / job can be calculated by using the below expression :</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>sum</span> <span style=color:#66d9ef>by</span> (job)(scrape_samples_scraped)
</span></span></code></pre></div><p><img alt="samples scraped" loading=lazy src=/sample-scraped.png></p><h3 id=3-scrape-duration--prometheus_target_interval_length_seconds>3. Scrape duration : <code>prometheus_target_interval_length_seconds</code><a hidden class=anchor aria-hidden=true href=#3-scrape-duration--prometheus_target_interval_length_seconds>#</a></h3><p><em>metric type: Gauge</em></p><ul><li>You might also need to monitor the scrape duration heath of your Prometheus.</li><li>If the duration goes beyond a certain threshold value, the samples will get out of order.</li><li>More details & debugging out of order samples <a href=https://www.robustperception.io/debugging-out-of-order-samples>here</a>.</li></ul><p>P99 of the scrape duration can be calculated using the below expression :</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span>prometheus_target_interval_length_seconds<span style=color:#960050;background-color:#1e0010>{</span>quantile<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;0.9&#34;</span><span style=color:#960050;background-color:#1e0010>}</span>
</span></span></code></pre></div><p><img alt="scrape duration" loading=lazy src=/scrape-duration.png></p><p>I’ve listed above some important metrics you can look for, there’s lot more of them at <code>/metrics</code> endpoint of your Prometheus server.</p><hr><h2 id=grafana-dashboard>Grafana Dashboard<a hidden class=anchor aria-hidden=true href=#grafana-dashboard>#</a></h2><p>For quicker insights, I’ve made a Grafana dashboard from all the above expressions mentioned.</p><p>Which looks like this :</p><p><img alt="Grafana dashboard" loading=lazy src=/dashboard-1.png></p><p><img alt="Grafana dashboard" loading=lazy src=/dashboard-2.png></p><p>You can import the JSON file from <a href=https://github.com/tanmay-bhat/grafana-dashbaords>here</a> to your Grafana instance to get started.</p><hr><h2 id=references->References :<a hidden class=anchor aria-hidden=true href=#references->#</a></h2><p><a href=https://www.omerlh.info/2019/03/04/keeping-prometheus-in-shape/>https://www.omerlh.info/2019/03/04/keeping-prometheus-in-shape/</a></p><p><a href=https://prometheus.io/docs/prometheus/latest/getting_started/#configuring-prometheus-to-monitor-itself>https://prometheus.io/docs/prometheus/latest/getting_started/#configuring-prometheus-to-monitor-itself</a></p><p><a href=https://ganeshvernekar.com/blog/prometheus-tsdb-the-head-block/>https://ganeshvernekar.com/blog/prometheus-tsdb-the-head-block/</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://tanmay-bhat.github.io/tags/prometheus/>Prometheus</a></li><li><a href=https://tanmay-bhat.github.io/tags/grafana/>Grafana</a></li></ul><nav class=paginav><a class=prev href=https://tanmay-bhat.github.io/posts/configure-readiness-probe-alert-prometheus/><span class=title>« Prev</span><br><span>How to configure Readiness Probe alert in Prometheus</span>
</a><a class=next href=https://tanmay-bhat.github.io/posts/getting-started-with-argocd-image-updater/><span class=title>Next »</span><br><span>ArgoCD Image Updater with Digital Ocean Container Registry</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Self monitoring Prometheus with Grafana on x" href="https://x.com/intent/tweet/?text=Self%20monitoring%20Prometheus%20with%20Grafana&amp;url=https%3a%2f%2ftanmay-bhat.github.io%2fposts%2fprometheus-self-metrics%2f&amp;hashtags=Prometheus%2cGrafana"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self monitoring Prometheus with Grafana on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2ftanmay-bhat.github.io%2fposts%2fprometheus-self-metrics%2f&amp;title=Self%20monitoring%20Prometheus%20with%20Grafana&amp;summary=Self%20monitoring%20Prometheus%20with%20Grafana&amp;source=https%3a%2f%2ftanmay-bhat.github.io%2fposts%2fprometheus-self-metrics%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self monitoring Prometheus with Grafana on reddit" href="https://reddit.com/submit?url=https%3a%2f%2ftanmay-bhat.github.io%2fposts%2fprometheus-self-metrics%2f&title=Self%20monitoring%20Prometheus%20with%20Grafana"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self monitoring Prometheus with Grafana on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ftanmay-bhat.github.io%2fposts%2fprometheus-self-metrics%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self monitoring Prometheus with Grafana on whatsapp" href="https://api.whatsapp.com/send?text=Self%20monitoring%20Prometheus%20with%20Grafana%20-%20https%3a%2f%2ftanmay-bhat.github.io%2fposts%2fprometheus-self-metrics%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self monitoring Prometheus with Grafana on telegram" href="https://telegram.me/share/url?text=Self%20monitoring%20Prometheus%20with%20Grafana&amp;url=https%3a%2f%2ftanmay-bhat.github.io%2fposts%2fprometheus-self-metrics%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self monitoring Prometheus with Grafana on ycombinator" href="https://news.ycombinator.com/submitlink?t=Self%20monitoring%20Prometheus%20with%20Grafana&u=https%3a%2f%2ftanmay-bhat.github.io%2fposts%2fprometheus-self-metrics%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://tanmay-bhat.github.io/>Tanmay Bhat</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>