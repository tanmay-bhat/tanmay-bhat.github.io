<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubernetes on Tanmay Bhat</title>
    <link>https://tanmay-bhat.github.io/tags/kubernetes/</link>
    <description>Recent content in Kubernetes on Tanmay Bhat</description>
    <image>
      <title>Tanmay Bhat</title>
      <url>https://tanmay-bhat.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://tanmay-bhat.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 30 Jan 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://tanmay-bhat.github.io/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How to Configure Alerting on Ingress-NGINX in Kubernetes</title>
      <link>https://tanmay-bhat.github.io/posts/slo-based-alert-on-ingress-nginx/</link>
      <pubDate>Mon, 30 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://tanmay-bhat.github.io/posts/slo-based-alert-on-ingress-nginx/</guid>
      <description>In this blog post, we will be discussing how to set up monitoring and alerting for Nginx ingress in a Kubernetes environment.
We will cover the installation and configuration of ingress-nginx, Prometheus and Grafana, and the setup of alerts for key Ingress metrics.
Pre-requisites : A Kubernetes cluster Helm v3 Install Prometheus and Grafana In this step, we will install Prometheus to collect metrics, and Grafana to visualize and create alerts based on those metrics.</description>
    </item>
    <item>
      <title>Automate Your Helm Chart Testing Workflow with GitHub Actions</title>
      <link>https://tanmay-bhat.github.io/posts/helm-chart-testing-github-actions/</link>
      <pubDate>Tue, 27 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://tanmay-bhat.github.io/posts/helm-chart-testing-github-actions/</guid>
      <description>Helm is a popular open-source package manager for Kubernetes that simplifies the process of installing, upgrading, and managing applications on a Kubernetes cluster. Helm packages, called charts, contain all the necessary resources and configuration for deploying an application on a Kubernetes cluster.
As with any software project, it&amp;rsquo;s important to test charts before deploying them to ensure that they are reliable and function as intended. Chart testing is the process of verifying the functionality and correctness of a Helm chart before it is deployed to a Kubernetes cluster.</description>
    </item>
    <item>
      <title>How to enable Google SSO in Kibana using OAuth2 Proxy [Kubernetes]</title>
      <link>https://tanmay-bhat.github.io/posts/google-sso-kibana/</link>
      <pubDate>Mon, 30 May 2022 00:00:00 +0000</pubDate>
      <guid>https://tanmay-bhat.github.io/posts/google-sso-kibana/</guid>
      <description>OAuth2 Proxy is a reverse proxy that provides authentication using Providers such as Google, GitHub, and others to validate accounts by email, domain or group.
In this article, we’ll setup and configure OAuth2 Proxy to enable Google SSO for Kibana in Kubernetes.
Prerequisite: Kibana in Kubernetes Nginx Ingress Setup Google Credentials In Google Cloud Console, select OAuth consent screen Select the User Type as : “Internal” Complete the app registration form with your Authorized domain, then click Save.</description>
    </item>
    <item>
      <title>How to configure Readiness Probe alert in Prometheus</title>
      <link>https://tanmay-bhat.github.io/posts/configure-readiness-probe-alert-prometheus/</link>
      <pubDate>Tue, 29 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://tanmay-bhat.github.io/posts/configure-readiness-probe-alert-prometheus/</guid>
      <description>This article aims to explain the steps to configure Readiness Probe failure alert in Prometheus.
Definition : Readiness Probe in Kubernetes is a probing mechanism to detect health (ready status) of a pod and if the health is intact, then allow the traffic to the pod.
From the official doc,
Sometimes, applications are temporarily unable to serve traffic. For example, an application might need to load large data or configuration files during startup, or depend on external services after startup.</description>
    </item>
    <item>
      <title>How to scale down Kubernetes cluster workloads during off hours</title>
      <link>https://tanmay-bhat.github.io/posts/how-to-scale-down-kubernetes-cluster-workloads-during-off-hours/</link>
      <pubDate>Thu, 06 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://tanmay-bhat.github.io/posts/how-to-scale-down-kubernetes-cluster-workloads-during-off-hours/</guid>
      <description>You heard it right, everyone needs to rest once a while, even our little Kubernetes cluster. Before we begin, here are the prerequisites :
Kubernetes cluster Cluster autoscaler Bit of patience Usecase : One of the most important aspect when it comes to running workload in cloud is to keep cost under control or tune it such that you can save extra. You maybe hosting workload in Kubernetes where you wont get traffic post business hours.</description>
    </item>
  </channel>
</rss>
